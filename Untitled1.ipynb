{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import urllib.request\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_urls(base_url,interval,count=-1):\n",
    "    \"\"\" baseUrl is https://www.sec.gov/cgi-bin/own-disp?action=getissuer&CIK=0000320193\n",
    "        the next page is \n",
    "        https://www.sec.gov/cgi-bin/own-disp?action=getissuer&CIK=0000320193&type=&dateb=&owner=include&start=80\n",
    "    \"\"\"\n",
    "    all_urls = []\n",
    "    header = {'User-Agent':'Mozilla/5.0 (X11; Fedora; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "    try: \n",
    "        request = urllib.request.Request(base_url,headers=header)\n",
    "        file = urllib.request.urlopen(request)\n",
    "    except:\n",
    "        print(\"Fail to open\", base_url)\n",
    "        return all_urls\n",
    "    all_urls.append(file)\n",
    "    url_ext = '&type=&dateb=&owner=include&start='\n",
    "    index = interval\n",
    "    while True:\n",
    "        try: \n",
    "            new_url = base_url+url_ext+str(index)\n",
    "            print('opening',new_url)\n",
    "            file = urllib.request.urlopen(new_url)\n",
    "        except:\n",
    "            print(\"Fail to open\",new_url)\n",
    "            break\n",
    "        index += interval\n",
    "        all_urls.append(file)\n",
    "        if len(all_urls) > 10:\n",
    "            break\n",
    "    return all_urls\n",
    "\n",
    "def parse_officer_info(tags, sub_tag='td'):\n",
    "    name = ''\n",
    "    date = ''\n",
    "    title = ''\n",
    "    owner_info = []\n",
    "    all_tds = tags.findAll(sub_tag)\n",
    "    if len(all_tds) != 4:\n",
    "        return owner_info\n",
    "    matchOfficer = re.search('^officer:\\s+(.*?)$', all_tds[3].string)\n",
    "    if matchOfficer:\n",
    "        title = '\"'+matchOfficer.group(1)+'\"'\n",
    "    else:\n",
    "        return owner_info\n",
    "    date = all_tds[2].string\n",
    "    name = '\"'+all_tds[0].string+'\"' \n",
    "    return (name, date, title)\n",
    "def parse_stock_transaction(tags, sub_tag='td'):\n",
    "    all_tds = tags.findAll(sub_tag)\n",
    "    transaction_info = []\n",
    "    if len(all_tds) != 12 or (len(all_tds)==12 and all_tds[4].string != '4'):\n",
    "        return transaction_info\n",
    "    sell_or_buy = all_tds[0].string\n",
    "    date = all_tds[1].string\n",
    "    name = '\"'+all_tds[3].string+'\"'\n",
    "    transaction_type = all_tds[5].string\n",
    "    nums_of_transacted = all_tds[7].string\n",
    "    total_securities = all_tds[8].string\n",
    "    \n",
    "    return (name,date,sell_or_buy,transaction_type, nums_of_transacted, total_securities)\n",
    "\n",
    "def write_list_to_file(file_obj, to_write_list):\n",
    "    for my_line in to_write_list:\n",
    "        my_line = ' '.join(str(item) for item in my_line)\n",
    "        file_obj.write(my_line+\"\\n\")\n",
    "    return\n",
    "def parse_sec_url_obj(file_obj):\n",
    "    if len(file_obj) == 0 or file_obj == None:\n",
    "        return 0\n",
    "    # parse the 1st page to get the owner info once\n",
    "    owner_infos = []\n",
    "    owner_html = file_obj[0].read().decode('utf-8')\n",
    "    owner_sp = BeautifulSoup(owner_html)\n",
    "    company_name = owner_sp.title.string\n",
    "    owner_pattern = re.search('Ownership Information:\\s+(.*?)$', company_name)\n",
    "    company_name = '_'.join(owner_pattern.group(1).split())+\".csv\"\n",
    "    output = open(company_name,'w')\n",
    "    print(\"Writing\",company_name,\"file ...\")\n",
    "    for tr in owner_sp.findAll('tr'):\n",
    "        owner_info = parse_officer_info(tr)\n",
    "        if len(owner_info) > 0:\n",
    "            owner_infos.append(owner_info)\n",
    "            \n",
    "    if len(owner_infos)==0:\n",
    "        print(\"Error: no owner info\")\n",
    "        return -1\n",
    "    write_list_to_file(output, owner_infos)\n",
    "\n",
    "    index = 0\n",
    "    for single_url_obj in file_obj:\n",
    "        transaction_infos = []\n",
    "        my_html = \"\"\n",
    "        if index == 0:\n",
    "            my_html = owner_html\n",
    "        else:\n",
    "            my_html = single_url_obj.read().decode('utf-8')\n",
    "        sp = BeautifulSoup(my_html)\n",
    "        for tr in sp.findAll('tr'):\n",
    "            transaction_info = parse_stock_transaction(tr)\n",
    "            if len(transaction_info) > 0:\n",
    "                transaction_infos.append(transaction_info)\n",
    "        write_list_to_file(output, transaction_infos)\n",
    "        index += 1\n",
    "    output.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening https://www.sec.gov/cgi-bin/own-disp?action=getissuer&CIK=0000320193&type=&dateb=&owner=include&start=80\n",
      "opening https://www.sec.gov/cgi-bin/own-disp?action=getissuer&CIK=0000320193&type=&dateb=&owner=include&start=160\n",
      "opening https://www.sec.gov/cgi-bin/own-disp?action=getissuer&CIK=0000320193&type=&dateb=&owner=include&start=240\n",
      "opening https://www.sec.gov/cgi-bin/own-disp?action=getissuer&CIK=0000320193&type=&dateb=&owner=include&start=320\n",
      "opening https://www.sec.gov/cgi-bin/own-disp?action=getissuer&CIK=0000320193&type=&dateb=&owner=include&start=400\n",
      "opening https://www.sec.gov/cgi-bin/own-disp?action=getissuer&CIK=0000320193&type=&dateb=&owner=include&start=480\n",
      "opening https://www.sec.gov/cgi-bin/own-disp?action=getissuer&CIK=0000320193&type=&dateb=&owner=include&start=560\n",
      "opening https://www.sec.gov/cgi-bin/own-disp?action=getissuer&CIK=0000320193&type=&dateb=&owner=include&start=640\n",
      "opening https://www.sec.gov/cgi-bin/own-disp?action=getissuer&CIK=0000320193&type=&dateb=&owner=include&start=720\n",
      "opening https://www.sec.gov/cgi-bin/own-disp?action=getissuer&CIK=0000320193&type=&dateb=&owner=include&start=800\n"
     ]
    }
   ],
   "source": [
    "myurl = 'https://www.sec.gov/cgi-bin/own-disp?action=getissuer&CIK=0000320193'\n",
    "all_urls = get_all_urls(myurl,80)\n",
    "parse_sec_url_obj(all_urls)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing APPLE_INC.csv file ...\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_name_is_hujin_zhen\n"
     ]
    }
   ],
   "source": [
    "hello = \"my name is hujin zhen\"\n",
    "print('_'.join(hello.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stock_forcasting]",
   "language": "python",
   "name": "conda-env-stock_forcasting-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
